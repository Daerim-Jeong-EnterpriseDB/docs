---
title: "EDB Postgres Distributed Proxy"
navTitle: "PGD Proxy"
indexCards: none
navigation:
- installing_proxy

directoryDefaults:
  description: "The PGD Proxy is a service that acts as proxy layer between the client application and Postgres for your EDB Postgres Distributed cluster"
---

EDB Postgres Distributed Proxy is a daemon that acts as an abstraction layer between the client application and Postgres. It interfaces with the PGD consensus mechanism to get the identity of the current write leader node and redirects traffic to that node.

The PGD cluster always has at least one global group and one data group. PGD elects the write leader for each data group that has the `enable_proxy_routing` and `enable_raft` options set to true. You can attach Proxy to a global group or data group. You can attach multiple proxies to each group.

PGD Proxy is a TCP layer 4 proxy.

## How it works

Upon starting, PGD Proxy connects to one of the endpoints given in the local config file. It fetches:

-  DB connection information for all nodes
-  Proxy options like listen address, listen port
-  Routing details like current write leader

Endpoints given in the config file are used only at startup. After that, actual endpoints are taken from the PGD catalog's `route_dsn` field in `bdr.node_routing_config_summary`.


PGD manages write leader election. PGD Proxy interacts with PGD to get write leader change events notifications on Postgres notify/listen channels and routes client traffic to the current write leader. PGD Proxy disconnects all existing client connections on write leader change or when write leader is unavailable. Write leader election is a Raft-backed activity and is subject to Raft leader availability. Proxy will close the new client connections if write leader is unavailable.

PGD Proxy responds to write leader change events that can be categorized into two modes of operation: *failover* and *switchover*.

Automatic transfer of write leadership from the current write leader node to a new node in the event of Postgres or operating system crash is called failover. PGD elects a new write leader when the current write leader goes down or becomes unresponsive. Once the new write leader is elected by PGD, proxy closes existing client connections to the old write leader and redirects new client connections to the newly elected write leader.

User-controlled, manual transfer of write leadership from the current write leader to a new target leader is called switchover. Switchover is triggered through the [PGD CLI switchover](../cli/command_ref/pgd_switchover) command. The command is submitted to PGD, which attempts to elect the given target node as the new write leader. Similar to failover, PGD Proxy closes existing client connections and redirects new client connections to the newly elected write leader. This is useful during server maintenance, for example, if the current write leader node needs to be stopped for maintenance like a server update or OS patch update.

### Consensus Grace Period

PGD Proxy provides the consensus_grace_period proxy option that can be used to configure the routing behavior upon loss of a Raft leader. Proxy will continue to route to the current write leader (if it is available) for this duration. If the new Raft leader is not elected during this period, the proxy will stop routing. If set to `0s` proxy will stop routing immediately.

The main purpose of this option is to allow users to configure the write behaviour when the Raft leader is lost. When the Raft leader is not present in the cluster it is not always guaranteed that the current write leader seen by the proxy is the correct one. In some cases, like network partition in the following example, it is possible that the two write leaders may be seen by two different proxies attached to the same group increasing the chances of write conflicts. If this is not the desired behavior then the previously mentioned  consensus_grace_period can be set to 0s. This setting configures the proxy to stop routing and close existing open connections immediately when it detects the Raft leader is lost.

#### Network partition example

Consider a 3 data node group with a proxy on each data node. In this case, if the current write leader gets network partitioned or isolated then the data nodes present in the majority partition will elect a new write leader. If `consensus_grace_period` is set to a non-zero value say `10s` then the proxy present on the previous write leader will continue to route writes for this duration.

Note: In this case, if the grace period is kept too high then writes will continue to happen on the two write leaders increasing the chances of write conflicts.

Having said that, most of the time, upon loss of the current Raft leader the new Raft leader gets elected by BDR within a few seconds provided more than half of the nodes (quorum) are still up. Hence, if the Raft leader is down but the write leader is still up then proxy can be configured to allow routing by keeping `consensus_grace_period` to a non-zero, positive value. The proxy will wait for the Raft leader to get elected during this period before stopping routing. This may be helpful in some cases where availability is more important.

### Proxy health check

If enabled proxy exposes following two http health check endpoints that can be used as liveness and readiness probes in HA deployments. These endpoints are http `GET` requests and do not require a request body.
```
/health/is-live
/health/is-ready
```


#### Configuration

By default the proxy health check is disabled. It can be enabled by simply adding the config `http.enable = true` under `proxy` section in the `pgd-proxy-config.yml` file as shown below.
```
  proxy:
	  name: proxy-a1
	  endpoint: "host=proxy-a1 port=6432 dbname=bdrdb user=pgdproxy "
	  http:
  	  enable: true
```

Default http server address is `:8080` with timeout `10s`. Below is a sample config to set the custom values of host, port and timeout.
```
  proxy:
	  name: proxy-a1
	  endpoint: "host=proxy-a1 port=6432 dbname=bdrdb user=pgdproxy "
	  http:
  	  enable: true
  	  host: "0.0.0.0" # default is ":8080"
  	  port: 8080
	    probes:
  	    timeout: 10s
```

The `proxy.endpoint` parameter is used by readiness check which try to connect to the proxy server using this endpoint. Host and port given in the endpoint should be of proxy (e.g. host=proxy-a1 port=6432). Please note this is different from cluster endpoints where host and port are of the backend BDR server. User and database could be the same as per setup though.

The `proxy.probes.timeout` is used by readiness check. Readiness probe will return false if proxy doesn't return the result of query `select 1` within this time period. This value should be set based on failover time which varies from 1s to 25s and retry attempts to avoid false positives.

Proxy user (`pgdproxy` in above example) should have the database login access and its password set up in `~/.pgpass` file. If cluster is setup through TPAExec, it creates the `pgdproxy` user as an OS user as well as database user with `bdr_superuser` role and have it password set in the `pgpass` file.

#### Liveness check

Liveness check either return `true` with http status code `200 (OK)` or an error but never `false`. This is due to the fact that Proxy service exits immediately effectively stopping http server if it finds a critical error on startup that cannot be recovered or prevents further operations.

#### Readiness check

Readiness check returns `true` with http status code `200 (OK)` if the proxy is up and running. It returns `false` with http status code `500 (Internal Server Error)` if SQL query (`select 1`) fails through the given proxy's endpoint. It will return `false` in the following scenarios.
* Proxy detects that the Raft leader is not available and `consensus_grace_period` has expired.
* Proxy detects that the write leader is not available.
* Proxy cannot establish a TCP connection to the current write leader
* The TLS certificate on the current write leader is expired

Having that said, it is important to know that once started proxy always remains in available state even if these probes return false because the proxy can recover itself automatically (self heal) once the BDR side or connectivity issues are resolved.

!!! Note
    Proxy would execute the SQL query only when the readiness endpoint is requested and not on periodic basis.

## Managing PGD Proxy

PGD CLI provides a few commands to manage proxies in a PGD cluster, such as `create-proxy`, `delete-proxy`, `set-proxy-options`, and `show-proxies`. See [PGD CLI](../cli/command_ref) for more information.

See [Connection management](../routing) for more information on the PGD side of configuration and management of PGD Proxy.

## Proxy log location

### syslog

- Debian based - `/var/log/syslog`
- Red Hat based - `/var/log/messages`

Use the `journalctl` command to filter and view logs for troubleshooting Proxy. The following are few sample commands for quick reference:

```sh
journalctl -u pgd-proxy -n100 -f
journalctl -u pgd-proxy --since today
journalctl -u pgd-proxy --since "10 min ago"
journalctl -u pgd-proxy --since "2022-10-20 16:21:50" --until "2022-10-20 16:21:55"
```
